Cloud Dataprocクラスタを作成して、そのクラスタでのワーカー数を変更し、簡単なApache Sparkジョブを送信する方法を説明します
GCP Consoleです
まずはCloud Dataprocに移動します
だいぶ下ですが[ビッグデータ]まで移動すると、[Dataproc]があります
すでにクラスタがないか確認されますが、今回はないので先に進みクラスタを作成しましょう
まず名前を定義します
ここではexample-clusterという名前にします
他の設定は変更しませんが、簡単に紹介します
クラスタを保存するリージョンやゾーンを定義したり、ノードとワーカーの関係を定義するモードの種類を指定したりできます
ここでは１個のマスターと複数のワーカーが必要ですが、高可用性の設定で３個のマスターとワーカーの名前を定義することもできます
マスターノードではマシンタイプを選択できます
４個のvCPUです
次にワーカーの設定があります
ここにも４個のvCPUが２つ存在します
したがってこの設定では合計12個のvCPUが作成されます
[詳細オプション]でノードの一部をプリエンプティブルにしたり、ネットワーク、サブネットワーク、ファイアウォールルールに対するネットワークタグを定義したりできます
また、[内部IPのみ]、[Cloud Storageステージングバケット]、[イメージ]から最後の[暗号化]までさまざまなオプションがあります
それではデフォルトの構成でクラスタを作成しましょう
[作成]をクリックすると、さまざまなマシンが作成されます
別のタブを開いてCompute Engineに移動すると、生成中のすべてのインスタンスを確認できます
それでは移動しましょう
Dataprocはマネージドサービスですが、すべてのインスタンスを確認できます
生成された１個のマスターノードと２個のワーカーノードがあり、それぞれに先ほど指定した名前とマスターには-m、ワーカーには-wが付き、インデックスは０から始まります
元のタブに戻って更新すると、クラスタ自体はまだ初期化中です
ソフトウェアのインストールとすべての設定がバックエンドで行われています
クラスタの準備ができたら、そのサイズを変更できます
現在２個のワーカーノードがあるので、これを３個のワーカーノードなどに変更できます
その後は実際にジョブを送信します
ご覧のとおり数分かかりましたが、生成されたクラスタが稼働しています
クラスタ自体をクリックすると、詳細情報を確認できます
ここにはさまざまなモニタリング設定があります
VMインスタンスには各インスタンスが表示され、マスターにSSH接続できます
ジョブはまだないので、表示されていません
[構成]をクリックすると、現在２個のワーカーノードがあります
[編集]をクリックすると数を変更できます
たとえば３個のワーカーノードが必要な場合は、これを３に変更して[保存]をクリックすると、変更に応じて更新リクエストが送信されます
もう１個のワーカーが作成されてマスターも更新されるため、新しいワーカーが作成されたことがマスターに伝わります
そのためジョブの送信時にはすべてのワーカーを使用できます
Compute Engineに戻ると、新しいワーカーがすでに稼働していることがわかります
Dataprocに戻って更新すると、クラスタ自体はまだ更新中であることがわかります
この更新速度もかなり速く数分で終わります
Dataprocはマネージドサービスですが、使用されている実際のバックエンドインスタンスを確認できます
ここでクラスタの更新が完了したことがわかります
クラスタをもう一度クリックして、構成に移動すると、ワーカーノードが３個になったことがわかります
ではジョブを送信しましょう
[ジョブ]に移動して、[ジョブの送信]をクリックします
ここで、ジョブIDとリージョンはそのままにします
特に複数のクラスタがある場合は、当然ながらクラスタを選択します
この例では[ジョブタイプ]を[Spark]にします
メインクラスを定義します
これはクラスの例に含まれています
ここでやろうとしているのは、円周率の値を計算する例の作成です
したがって[引数]には1000を入力して、JARファイルを追加します
その下を見ると、プロパティやラベルなども追加できます
準備ができたので[送信]をクリックすると、ジョブの送信が開始されます
実行中のジョブのステータスアイコンがここに表示されます
ジョブ自体をクリックすると、このように実行中のジョブを実際に確認できます
構成をもう一度確認すると、先ほど指定したさまざまな設定がすべて表示されます
[出力]に戻りましょう
繰り返しますがここでは円周率の値を推定する大まかな計算を行っています
計算が終わると、大まかな円周率が表示されます
これでジョブは完了しました
クラスタがもう必要ない場合は削除できます
そうでなければ他のジョブを送信できますが、今回ではこれで完了です
したがってクラスタに戻り、これを選択して[削除]をクリックします
データもすべて削除されて、元に戻せなくなります
[OK]をクリックします
Compute Engineに移動して更新すると、すべてのインスタンスがすでに停止中で、その後に削除されることがわかります
このようにクラスタを簡単にスピンアップして削除できるため、必要に応じて使った分しか料金がかかりません
クラスタが削除されるまで待ちましょう
ほんの数分で削除されましたね
このとおりクラスタ自体が削除されています
インスタンスに移動すると、すべてのインスタンスも削除されています
このようにCloud Dataprocクラスタを作成し、そのクラスタにジョブを送信するのは簡単です
