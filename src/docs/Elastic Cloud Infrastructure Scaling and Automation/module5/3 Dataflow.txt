Cloud Dataflowについて少し説明します
Dataflowはマネージドサービスで、さまざまなデータ処理パターンの実行に対応しています
基本的にはフルマネージドサービスで、信頼性と表現力を損なうことなく、ストリーミングモードやバッチモードのデータを変換または拡張します
Dataflowでは、複雑なインフラの設定とメンテナンスの多くが自動的に処理されます
Google Cloudのインフラ上に構築され、データパイプラインの要求に応じて自動スケーリングされます
毎秒数百万件のクエリまでインテリジェントにスケーリング可能です
Dataflowは迅速かつ簡素化されたパイプライン開発ができるように、Apache Beam SDKに含まれる表現力豊かなSQL、Java、Python APIを利用します
このSDKはウィンドウ処理とセッション分析の多様なプリミティブを含み、ソースとシンクのコネクタからなるエコシステムも備えています
DataflowはStackdriverのような他のGCPサービスとも緊密に連携しているため、優先度の高いアラートや通知を設定して、パイプラインや入出力データの品質をモニタリングできます
この図はDataflowのユースケースの例です
前述のとおりDataflowはストリームデータとバッチデータを処理します
このデータはCloud Datastoreや、Googleのメッセージング、公開サービスであるCloud Pub/Subなど、他のGCPサービスから取得できます
またApache AvroやApache Kafkaなどのサードパーティ製サービスからもデータを取り込めます
Dataflowでデータを変換した後は、BigQueryやAI Platform、Cloud Bigtableで分析できます
データポータルを使えばIoTデバイス用に、リアルタイムのダッシュボードを構築することも可能です
