まず、マイクロサービスの詳細を確認しましょう
マイクロサービスは、大規模なプログラムを小さな独立したサービスに分割します
右の図のようになります
対照的に、モノリシックなアプリは単一のコードベースに全機能を実装し、１つのDBに全データを格納します
左の図のようになります
現在、マイクロサービスは業界のトレンドですが、このアーキテクチャを選択する場合は正当な理由があることが重要です
主な理由は、複数のチームが独立して作業し、各チームのペースで本番環境に配信できるようにすることです
こうすると組織の拡大に対応でき、チームを増やしてスピードを上げられます
また、要件に基づいて、個別にマイクロサービスをスケールできるという利点もあります
モノリスとして設計したアプリまたはマイクロサービスを中心としたアプリは、境界を明確に定義したモジュール式のコンポーネントで構成する必要があります
モノリスの場合は、全コンポーネントをデプロイ時にパッケージ化してデプロイします
マイクロサービスの場合は、コンポーネントを個別にデプロイできます
Google Cloudには、マイクロサービスのデプロイを容易にするサービスが複数あります
App Engine、Cloud Run、GKE、Cloud Functionsなどで、それぞれ粒度と制御のレベルが異なります
この点については後ほど説明します
各マイクロサービスを独立させるには、サービスごとに固有のデータストアを使用します
こうすると各サービスに最適なデータストアソリューションを選択でき、サービスの独立性も維持できます
データストアを介してサービス同士を結合させないことが重要です
マイクロサービスアーキテクチャを正しく設計すると、次の目標を達成できます
各種マイクロサービスの間に厳密なコントラクトを定義する
ロールバックを含む独立したデプロイサイクルを可能にする
サブシステムでの同時A/Bリリーステストを容易にする
テスト自動化と品質保証のオーバーヘッドを最小化する
ロギングとモニタリングの明確さを高める
細かい粒度で費用を計算する
小さなユニットをスケールすることで、アプリ全体のスケーラビリティと信頼性を高める
ただし、このアーキテクチャの利点だけではなく、課題も同時に検討する必要があります
次のような課題があります
各サービスを個別に開発、デプロイするためのサービス間の明確な境界は簡単に定義できない場合があります
インフラが複雑化し、配信するサービスの障害点が多くなります
ネットワークサービスによって、レイテンシが増加するため、障害や遅延に対処するためのレジリエンスを組み込む必要があります
ネットワークを使用することからサービス間の通信をセキュリティで保護する必要があり、その結果、インフラの複雑さが増します
個別にデプロイ可能なサービスの場合、サービスインターフェースの管理とバージョニングの要件が厳しくなり、下位互換性の必要性も増します
アプリをマイクロサービスに分解することは、アプリを設計する際に技術面での大きな課題の１つとなります
ドメインドリブンの設計といった手法は、機能を論理的なグループに分ける場合に有用です
この手法ではまず、依存関係が最小限になるように、アプリを機能別または機能グループ別に分解します
例として、小売向けオンラインアプリを考えてみます
論理機能グループには、商品管理、レビュー、アカウント、注文などがあります
こうしたグループをミニアプリにして、各ミニアプリでAPIを公開します
ミニアプリのそれぞれは、おそらく複数のマイクロサービスで実装されることになります
これらのマイクロサービスを内部でアーキテクチャレイヤ別に編成すれば、各サービスを個別にデプロイしスケーリングできます
分析を行うと、認証などの共有サービスが明らかになってきます
共有サービスは分離し、ミニアプリとは別にデプロイします
マイクロサービスを設計する場合、自身では状態を維持せずに、環境やステートレスサービスから状態を取得するようにすると管理が容易になります
自身で状態を維持しなければ、スケーリングや管理、新しいバージョンへの移行も簡単になります
ただし、マイクロサービスベースのアプリではある時点でステートフルサービスを使用せざるを得ないのが一般的です
そのため、ステートフルサービスがシステムのアーキテクチャに与える影響を理解しておく必要があります
たとえば、サービスのスケーリングとアップグレードに大きな影響をもたらします
状態がどのように管理されるかについて、マイクロサービスアプリ設計のごく早い段階で理解することが重要です
そのために役立つ提案と、ベストプラクティスをいくつか紹介します
メモリで状態を共有すると、マイクロサービスアーキテクチャの利点の多くが打ち消されてしまいます
たとえばマイクロサービスを個別に自動スケーリングできなくなります
後続のクライアントリクエストを、最初のリクエストに対応したサーバーに送信する必要があるからです
また、スティッキーセッションを使用するようにロードバランサを構成する必要があります
これは、Google Cloudではセッションアフィニティと呼ばれます
ステートフルサービス設計でよく知られているベストプラクティスは、フロントエンドステートレスサービスとバックエンドストレージを共有することです
たとえば、状態を永続的に保存するには、Google CloudマネージドデータサービスのFirestoreやCloud SQLなどが適しています
さらに、データをキャッシュに保存すればデータアクセス速度が向上します
高可用性のRedisベースのMemorystoreサービスはキャッシュに理想的です
この図に示すのは、フロントエンドとバックエンドの処理ステージを分離する一般的なソリューションであり、ロードバランサでバックエンドとフロントエンドのサービスに負荷を分散します
これにより、フロントエンドからの需要に応じてバックエンドをスケールできます
さらに、ステートフルサービスやサーバーも分離されます
したがってステートフルサービスは、前に説明した永続ストレージサービスとキャッシュを活用できます
このレイアウトにすると、アプリの大部分がGoogle Cloudサービスの拡張性と耐障害性をステートレスサービスとして利用できます
ステートフルサーバーおよびサービスを分離することで、スケーリングとアップグレードの課題がサービスセット全体のサブセットに限られます
