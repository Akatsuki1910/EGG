このラボではGoogle Cloudのツールを使って、自動化されたシンプルなCIパイプラインの作成方法を学びました
Cloud Source Repositoriesを使って、Gitリポジトリを作成し、Cloud Buildとトリガーを使ってリポジトリへのコードチェックイン時のDockerイメージの作成を自動化しました
Cloud Buildでは作成されたDockerイメージがContainer Registryに保存されます
これらのイメージにGCE VMでアクセスしてテストする方法を確認しました
これからラボのチュートリアルを行いますが、Google CloudのUIは変更されることがあるので、実際の環境と表示が異なる場合があります
GCP Consoleに移動しています
まず新しいリポジトリを作成します
それにはナビゲーションメニューで、[Source Repositories]までスクロールします
新しいタブが開きます
[リポジトリを追加]をクリックします
[新しいリポジトリを作成]をオンにして、続行します
ラボの手順で指示されている名前を付けます
“devops-repo”です
使用するプロジェクトを選択します
実際のQwiklabsプロジェクトを必ず選択してください
QwiklabsのUIに表示されているものです
選択したら[作成]をクリックします
作成されました
Cloud Consoleに戻ります
ここでタブを切り替えます
[Cloud Shellをアクティブにする]をクリックします
メッセージが表示されたら、[続行]をクリックします
Shellの表示面積はかなり小さいので、このアイコンを使って新しいウィンドウでShellを開きます
これで見やすくなります
新しいディレクトリを作成します
ラボの手順からディレクトリ名をコピーします
作成したディレクトリに移動します
作成した空のリポジトリを複製します
警告が出るはずです
空のディレクトリを使っているからです
このように空のディレクトリを複製したと表示されます
しかし問題なくこのディレクトリでdevops-repoフォルダを複製できたので、そこに移動します
移動しました
これで最初のタスクは完了です
次のタスクではコードエディタを使用して、この中に実際にファイルを作成します
これをクリックしてエディタを開きます
[File]メニューに移動して、新しいファイルを作成しますがdevops-repo内に作成する必要があります
devops-repoに移動してから、[File]、[New File]をクリックします
“main.py”という名前を付けます
正しいディレクトリ内に作成されました
このファイルの内容として、ラボの手順に記載されているPythonコードを貼り付けます
これを保存します
次は、templatesという新しいフォルダを作成します
devops-repoフォルダを右クリックして、[New Folder]を選択します
“templates”と名付けます
このフォルダ内にlayout.htmlというファイルを作成します
これもラボの手順どおりの名前です
こうした最初のステップでは、使用するコードを設定していきます
コードを複製するだけではなく、ファイルの内容を確認しながらコードの処理内容を理解していきます
これはシンプルなPythonアプリです
Hello Worldほど単純ではありませんが、これをパイプラインに使用します
このコースの他のラボでもこれと同様のものを使用します
index.htmlも作成する必要があります
templatesフォルダ内にさらにファイルを追加します
“index.html”と名付けます
ここにコードをコピーします
これも保存します
要件ファイルも必要です
これはPythonアプリでは、前提条件となっています
templatesフォルダ内にではなくdevops-repo内に作成します
新しいファイルを追加して、“requirements.txt”と名付けます
このファイルでFlaskを指定します
ここに指定します
これでいくつかのファイルを保存しました
次に、作成したすべてのファイルをローカルGitリポジトリに追加します
それにはCloud Shellでこのフォルダに移動します
ラボの手順では、cdを使ってフォルダに移動するように指示しています
もう少し広くして見やすいように、これをクリアしましょう
ここに移動したら、git add --allコマンドを実行します
これで、これまで行った変更がリポジトリにcommitされます
ラボの手順で推奨しているのは、メールアドレスとユーザー名を入力することです
Gmailでも他のメールアドレスでも好きなものを使ってください
この最初のconfigコマンドにメールアドレスを追加します
ここでは例として、Qwiklabsで私が使っているメールアドレスをコピーします
作業を続けます
たとえばここに、このセッション用のアドレスを貼り付けます
次に、ラボの手順に戻ります
ユーザー名を指定するためです
ここに指定します
メールアドレスのこの部分を使用できます
これは説明のためで、通常は独自のメールアドレスとユーザー名を設定します
これはデモにすぎません
Gitリポジトリを構成したので、実際に変更をcommitします
“Initial Commit”と名付けます
作成したファイルがすべて、commitに含まれています
devops-repoフォルダ直下にあるrequirementsに加え、main.pyもあります
templates内の２つのHTMLファイルもあります
これをマスターにpushします
処理が完了しました
これで[Source Repositories]ページに戻れます
ページを更新します
コードが表示されているので成功です
これで、タスク２を正常に完了できました
すべて順調ですが、このアプリのテストやDockerビルドなどの作成も必要です
そのためにCloud Shellに戻ります
最初にpipを使ってFlaskフレームワークをインストールするので、正しいフォルダに移動します
それにはcdコマンドを実行します
次に、sudo pip3 installを実行します
これが完了したら、このプログラムをpythonコマンドで実行します
ご覧のようにポート8080で実行されるように構成されています
実際に実行状況をプレビューできます
上の方に“ウェブでプレビュー”ボタンがあります
これをクリックして、[ポート8080でプレビュー]をクリックします
新しいタブが開きます
“Hello DevOps Fans”と表示されました
確認できたので停止します
それにはCloud Shellに戻って、Ctrl+Cで停止します
次に行う作業では、main.pyに移動してプログラム名を変更します
main.pyに移動すると、先ほど確認した“Hello DevOps Fans”が設定されています
このテキストを変更します
“Hello Google Cloud Fans.”に変更します
これを保存します
この変更を採用してcommitします
このcommitを“Second Commit”と名付けます
これをマスターにpushします
成功です
Cloud Source Repositoriesに戻って、main.pyに移動します
変更が反映されていることを確認できます
これでタスク３は完了です
次は創造力を働かせてDockerビルドを定義し、DevOpsパイプラインを操作します
最初に“Dockerfile”というファイルを作成し、このファイルでDockerコンテナの作成方法を定義します
Cloud Shellに戻ります
devops-repoフォルダ内に新しいファイルを作成します
拡張子なしで“Dockerfile”とだけ名付けます
Dockerfileです
ファイルの先頭に“FROM python:3.7”と入力します
これがベースイメージです
各種のベースイメージを選べますが、ここではインストール済みのPythonを使用します
その後に続けて“WORKDIR /app”と“COPY”と入力します
これらの行で現在のフォルダ内のソースコードをコンテナイメージ内のappフォルダにコピーします
さらにコマンドを追加します
pipを使用してPythonアプリの要件をコンテナにインストールするためです
ウェブアプリを実行するためにPythonウェブサーバーのgunicornも使用します
また、環境変数も入力します
アプリを実行するポートをこの場合は8080に指定します
最後の行で、gunicornウェブサーバーを使ってウェブアプリを実行します
このようになっています
画面を大きくしてファイル全体を見られるようにしましょう
ファイル全体の内容を確認できます
これをコピーして、すべて正しく設定されていることを再確認します
正しく設定されているようです
これがタスク４の作業でDockerビルドを定義しました
次はDockerイメージをCloud BuildとContainer Registryを使って管理します
Cloud Shellでまず現在の作業フォルダを確認します
ラボの手順で度々これを確認するわけは別の作業を行ったり、Cloud Shellを閉じて開いたりすると同じフォルダではなくなるからです
そのため現在の作業フォルダを確認する必要があります
これから環境変数を作成します
このプロジェクト専用のものですが、実際にはShellプロジェクトIDがあらかじめ格納されるので、それを確認します
echo ＄DEVSHELL_PROJECT_IDを実行するとプロジェクトIDが示されます
Consoleでも現在作業中のプロジェクトを確認できます
末尾が625cのプロジェクトです
ここでもそうなっています
作業を進めて、実際に環境変数を使用してビルドを開始しましょう
これが次の作業です
場合によってはCloud Buildを有効にするよう求められます
ダウンロード中です
完了するまで待ちます
Container Registry内のイメージ名は常に“gcr.io/”で始まります
その後に作業中のプロジェクトのプロジェクトID、イメージ名、バージョンが続きます
コマンド末尾のピリオドはDockerfileのパスを表します
この例の場合、現在の作業ディレクトリです
この処理が完了するのを待ってから、Consoleに戻りContainer Registryを確認します
完了しました
これが先ほど説明した“gcr.io”です
その後にプロジェクト名が続きます
さらにプロジェクト自体、バージョンが続きます
イメージ名とバージョンです
Container Registryに戻ります
Cloud Consoleで[Container Registry]をクリックします
画面を小さくします
devops-imageが示されています
次に行う作業として、Cloud Buildに移動してこのイメージを確認し、次にCompute Engineでこのコンテナイメージを使用するVMを作成します
ナビゲーションメニューに移動して、[Cloud Build]を選択します
長いリストの下のほうにあります
履歴を見ると、ビルドが50秒前に行われたことがわかります
保存場所などの詳細を表示するにはビルドをクリックします
さまざまな情報が表示され、問題があった場合もここで確認できます
とりあえずCompute Engineに移動しましょう
VMを作成します
[インスタンスの作成]ページで使用するのは、先ほど作成したコンテナイメージです
名前は“instance-1”のままにして、下にスクロールします
ここで重要なのは、[このVMインスタンスにコンテナイメージをデプロイします]をオンにすることです
使用するイメージをCloud Shellからここにコピーします
Cloud Shellに戻って、このパス全体を選択します
選択するとコピーされます
ここに貼り付けます
プロジェクトごとにパスは異なるため、このパスをコピーしないでください
プロジェクトIDが変われば、パスも変わります
また、HTTPトラフィックを許可する必要があります
それにはネットワークタグを追加して、ファイアウォールルールで許可するトラフィックにそのタグを設定します
こうするのはポート80で、トラフィックを有効にしたからです
[作成]をクリックします
このVMが起動するまで待ちます
その後、外部IPアドレスにリクエストを送信します
これは閉じておきます
新規プロジェクトでは、このような学習ページを使用できます
Qwiklabsの各種ラボでは常に新規プロジェクトを使用するため必ず用意されます
これが外部IPなので、クリックします
起動までにしばらく時間がかかり、１分ほど待つ必要があります
しばらく待ってから戻ってきましょう
コンテナが起動するまでに１、２分かかりましたが、変更後の新しいテキストが表示されています
稼働中になっているので、外部IPアドレスにリクエストを送信します
この例でのIPアドレスはこれなので、直接クリックすることもIPアドレスを入力して移動することもできます
次の作業でこれらの変更をGitリポジトリに保存します
Cloud Shellに戻ります
これをクリアしてスペースを設けます
正しい作業フォルダであることを確認してから、git add --allを実行します
Dockerサポートを追加したというメッセージを入力して、ローカルで変更をcommitします
これをマスターにpushします
うまくいったので、タブを切り替えてCloud Source Repositoryに戻ります
ページを更新します
Dockerfileも表示して、変更が反映されていることを確認します
ここまでは順調です
次は自動化の作業に取り掛かり、トリガーを使ってビルドを自動化します
Container Registryに移動します
別のタブが開くはずなので、これらのタブを閉じておきます
Cloud Consoleに戻り、ナビゲーションメニューを下にスクロールします
[Container Registry]を選択します
ここにdevops-imageフォルダがあります
フォルダ内には先ほど作成したコンテナがあります
次はCloud Buildに移動します
ナビゲーションメニューに戻ります
[Cloud Build]を選択します
トリガーを作成するので、[トリガー]セクションに移動します
[トリガーを作成]を選択します
devops-repoリポジトリに対して作成します
トリガー名はラボの手順のとおり“devops-trigger”とします
あとはデフォルト設定のままにし、トリガーのタイプもブランチにします
含めるファイルと除外するファイルイメージ名などを指定できますが、この例ではそのままの設定で作成します
トリガーが作成されたら実行してみます
[トリガーの実行]をクリックします
ビルドが開始されました
[履歴]のリンク先に移動して、実際に実行中であることを確認します
[履歴]に移動すると、ビルドがトリガーされたことを確認できます
完了するまで待ってから、このトリガーされたビルドをクリックします
これによって表示されるビルドのログを下にスクロールすると、マシンに対して実行される処理を確認できます
完了するまで待ってから、確認しましょう
完了しました
ビルドのリンクをクリックすると、処理内容を確認できます
先ほどと同じようにこれをCloud Shellから実行したとすると、この出力が表示されることになります
Container Registryサービスに戻ると、新しいイメージが追加されているはずです
ナビゲーションメニューに移動します
スクロールして、[Container Registry]を選択します
devops-imageがあります
devops-repoフォルダもあります
ここに新しいイメージがあります
失礼
間違った場所に移動していました
これが１分前に作成された新しいイメージです
確認できたので、次はファイルに変更を加えてビルドが自動的に行われる様子を確認し、これらのビルドの変更もテストします
Cloud Shellに戻ります
main関数に移動して、前と同じくこのタイトルを変更します
ラボの手順に記載されているように、“Hello Build Trigger.”に変更します
保存します
変更をcommitするので、まず現在の作業フォルダを確認します
次に変更をCloud Source Repositoriesにpushします
変更が追加されたので、ビルドがトリガーされるはずです
確認のために、ConsoleでCloud Buildサービスに戻ります
ビルドが自動的にトリガーされたことがわかります
これでタスク６は完了しました
ですが実際にテストする必要があるので、ビルドが完了するまで待ちます
完了したら、ビルドをクリックして詳細を確認します
表示されるビルド情報でイメージのリンクを見つけます
そのイメージで新しいVMを作成して新しく作成されたこのイメージをテストします
また、VMが起動したらHTTPトラフィックを開始して、テキストが変更されていることも確認します
“Hello Google Cloud Fans.”ではなく“Hello Build Triggers.”となっているはずです
ビルドが完了しました
ビルドをクリックします
イメージを見つけます
ビルドログをスクロールして調べることも、[ビルドアーティファクト]でイメージを見つけることもできます
スペースを広げてイメージ名をコピーします
ナビゲーションメニューに移動して、[Compute Engine]を選択し、Compute Engineで新しいインスタンスを作成します
[インスタンスを作成]をクリックします
名前、リージョンはデフォルトのままにします
重要なのはコンテナをデプロイするように設定して、イメージ名を貼り付けることです
HTTPトラフィックを許可して、この設定で作成します
このVMが起動するまで待ちます
起動したら外部IPアドレスをクリックします
前と同様に、コンテナが起動してからでないと準備は完了しないので待ちましょう
処理が完了して、コンテナが稼働中になり“Hello Build Trigger.”と表示されました
以上で終了です
