バージョン管理から見ていきましょう
マイクロサービスアーキテクチャの主な利点は、各サービスを独立してデプロイできることですが、それにはサービスAPIを保護する必要があります
バージョニングは必須であり、新しいバージョンのデプロイ時は必ず前のバージョンとの下位互換性を確保するようにします
これには単純な設計ルールが役立ちます
たとえばURIでバージョンを示したり、下位互換性のない変更を行うときはバージョンを変更したりします
SWの新しいバージョンのデプロイには、常にリスクが伴います
公開前に新しいバージョンを効率的にテストし、デプロイ準備ができたらダウンタイムなしでデプロイする必要があります
これらの目標達成に役立つ戦略を紹介します
ローリングアップデートでは、ダウンタイムなしでデプロイできます
一般的な構成ではロードバランサの背後に、サービスの複数インスタンスがあります
これらのインスタンスが一度に１つずつ更新されます
この戦略が適しているのは、APIが変更されない場合、下位互換性が維持される場合、更新中に同じサービスの２つのバージョンが実行されていても問題がない場合です
インスタンスグループにはローリングアップデートが組み込まれているため、更新時にローリングアップデート戦略を定義するだけで適用できます
Kubernetesでは、この戦略はデフォルトの設定です
よって置換後のDockerイメージのみ指定します
App Engineではこの戦略が、完全に自動化されています
サービスの複数バージョンを同時に実行できない場合は、Blue/Greenデプロイを使用します
Blue/Greenデプロイでは、２つの完全なデプロイ環境を使用します
Blueデプロイで現在デプロイ済みの本番環境SWを実行し、Greenデプロイ環境で更新後のSWバージョンをデプロイします
新しいSWバージョンをテストする場合は、Green環境にデプロイします
テストが完了したら、ワークロードを現在の（Blue）環境から新しい（Green）環境にシフトします
この戦略では問題が発生したら、前のデプロイに戻せるため、問題のある更新をデプロイした場合のリスクが軽減されます
Compute Engineでは、DNSを使ってリクエストを転送できます
Kubernetesではラベルを使って、新しいPodにルーティングするようサービスの構成を簡単に変更できます
App Engineでは、前のラボで確認したトラフィック分割を使用できます
ローリングアップデートの前に、カナリアリリースを使えばリスクを軽減できます
カナリアリリースでは、現在のデプロイの実行中に新しいデプロイを作成します
新しいデプロイにトラフィックのごく一部を送信してモニタリングします
新しいデプロイで確証が得られたら、新しいデプロイに送るトラフィックの割合を100%に達するまで増やしていきます
Compute Engineでは、新しいインスタンスグループを追加バックエンドとしてロードバランサに追加します
Kubernetesでは既存のPodと同じラベルを付けたPodを新規作成できます
これで、新しいPodにリクエストの一部が自動転送されるようになります
App Engineでもトラフィック分割機能を使用して、トラフィックの一部を転送できます
