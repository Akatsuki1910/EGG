このラボではバケットとオブジェクトを作成して操作し、次のCloud Storage機能を使用しました
顧客指定の暗号鍵、アクセス制御リスト、ライフサイクル管理、オブジェクトのバージョニング、ディレクトリ同期、IAMを使用したプロジェクト間でのリソース共有です
Cloud Storageの高度な機能の多くを理解したところで、これらの機能を活用した新しい多様なアプリを考え出してください
一般に、Cloud Storageをバックアップサービスとして使うと、GCPをすぐに使い始められます
ラボのチュートリアルの注意点として、GCPのUIは変更されることがあるので、実際の見た目とは異なる場合があります
Cloud Storageラボのチュートリアルにようこそ
私はすでにQwiklabsでラボを開始しているので、提供されたユーザー名とパスワードでGCP Consoleにログイン済みです
最初のタスクでは準備として、バケットを作成します
ここです
[バケットの作成]に移動すると、グローバルに一意のIDを使用するように書いてあるので、プロジェクトIDを使います
“myproj-”という名前にして、その後にプロジェクトIDを続けます
マルチリージョンにするので、ストレージクラスとして[マルチリージョン]を指定します
アクセス制御については、[オブジェクトレベルとバケットレベルの権限を設定]を指定して[作成]をクリックします
この時点で、ラボのページに戻って[進行状況を確認]をクリックすると、バケットを作成したのでチェックマークが付いて５ポイントもらえます
次のステップでは、ファイルをダウンロードするためにCloud Shellを起動して、curlコマンドを実行します
最初に、先ほど作成したバケットの名前に環境変数を設定して、コマンドのコピーと貼り付けが楽になるようにします
“export BUCKET_NAME_1=”の後にバケット名を続けます
機能することを確認するために、“echo $”と入力し、その後に変数名を続けると正しく設定されていることを確認できます
次はファイルをダウンロードします
一般公開されているHadoopドキュメントのHTMLファイルです
“ls”を実行すると、setup.htmlがあることを確認できます
これをコピーして、setup2とsetup3を作成します
“ls”を実行して、３つのファイルがあることを確認します
２つ目のタスクはACLです
このファイルをバケット内にコピーしてから、バケット用のアクセス制御リストを構成します
最初のgsutilコマンドで、setup.htmlをバケット内にコピーします
コピーされたら、このsetup.htmlに割り当てられている既定のアクセスリストを取得します
このリストはバケットベースで、設定されています
ファイルをacl.txtにパイプで渡したら、“cat”で確認します
これで、割り当てられているすべての権限を確認できます
これらの権限を限定公開に設定します
権限を限定公開に設定して、ファイルをacl2.txtにパイプで渡し、“cat”でその内容を確認します
限定公開に設定されたことを確認できます
次は、リストを更新してファイルを一般公開するために次のコマンドを実行します
ファイルをacl3にパイプで渡し、その内容を確認できるようにします
全ユーザーに読み取り可能になっています
これもラボのチェックポイントで、[進行状況を確認]をクリックすると、ファイルが正しく一般公開されていればチェックマークが付きます
次はConsoleを使って、バケット内にファイルがあり、一般公開されていることを確認します
確認する手段は、この小さなアイコンと、一般公開されていることを示すこの公開リンクです
次は、Cloud Shellのローカルインスタンスから、setup.htmlを削除します
ありました
検索から削除します
“ls”を実行するとsetup2とsetup3はありますが、setupはありません
削除されています
Cloud Shellインスタンスから、誤って削除してしまい
バケット内のファイルをローカルのCloud Shellに戻すとしたら、バケットからローカルCloud Shellにコピーするだけで戻せます
“ls”を再び実行すると、３つのsetupファイルを確認できます
３つ目のタスクでは、顧客指定の暗号鍵を生成します
鍵を生成するために、このコマンドを実行します
出力が表示されます
その後は、これをコピーできますが、まずはbotoファイルがあることを確認します
“ls -al”で確認できます
botoファイルはありません
そこで何をするかと言うと、“gsutil config -n”を実行します
それから“ls -al”を実行すると、botoファイルを確認できます
確認できたので、“nano.boto”を実行します
続いて、暗号鍵フィールドを見つけます
いったん閉じます
作成した鍵をコピーしなかったからです
鍵が必要です
ここにあります
これをコピーします
nanoに戻ります
“encryption_key”で始まる行を見つけます
拡大して見やすくします
decryption_keyの行の上にある、encryption_keyの行をコメント化解除します
ここに作成した鍵を貼り付けます
Ctrl+Oを押します
これでこのファイルを書き込んでから、Ctrl+Xでnanoを終了します
setupの次は、残りのsetup2とsetup3をバケットにアップロードします
setup2とsetup3です
Consoleに戻ります
下にスクロールして、バケットを更新します
この両方のファイルを見ると、顧客指定の暗号鍵で暗号化されていることを確認できます
この時点で進行状況を確認して、このステップでの作業ポイントを獲得できます
次の作業ではローカルファイルを削除するために、“rm setup*”を実行してsetup、setup2、setup3をすべて削除します
またバケットからファイルをコピーします
暗号化されたファイルが戻っているか、“cat”で確認します
確認できました
暗号化されていても、正常にファイルを取り戻せました
次は、現在の顧客指定の暗号鍵を復号鍵に移動します
そのため“nano.boto”と入力します
前に追加した行を見つけて、コメントアウトします
行番号をメモしておけば、再び探す必要はなかったのですが…
暗号鍵はgsutilセクションにあります
どこでしょう
もうすぐだと思います
探しています
ここです
encryption_keyの行をコメントアウトします
そして、decryption_key1をコメント化解除します
ありました
これをコピーして、decryption_key1に貼り付けます
保存します
Xで終了です
ベストプラクティスは、古い顧客指定の…顧客指定の暗号鍵を削除することですが、この例ではコピーして貼り付けます
新しい鍵を生成します
次にbotoファイルに戻ります
新しいencryption_key行を追加します
まずは、新しく作成した鍵をコピーします
同じ作業を繰り返します
行きすぎました
新しい“encryption_key=”を追加して、その後に新しい鍵を貼り付けます
Ctrl+Oで保存して、Ctrl+Xで終了します
次に、ファイル１の鍵を再作成して、古い復号鍵をコメントアウトします
botoに移動して、decryption_key1をコメントアウトします
今回はnanoを使用していますが、Cloud Shellエディタも使用できます
もしかしたら、このツールよりも少し使いやすいかもしれません
皆さん次第です
この鉛筆アイコンをクリックして、利用できます
decryption_key1を見つけましょう
もうすぐです
これをコメントアウトします
次に、保存します
暗号化します
setup2をダウンロードします
setup3もダウンロードします
どうなったでしょう
復号鍵をコメントアウトしたので、対応する鍵が見つかりません
当然です
このラボの最後のタスクでは、コマンドを実行して現在のライフサイクルポリシーを表示します
このコマンドです
ライフサイクル構成がないという結果なので、JSONライフサイクルポリシーファイルを作成します
ここに次のルールを貼り付けます
31日を経過したものは、削除するというルールです
書き込んだら終了します
このポリシーを設定するために、ボックスに記載されているコマンドを実行します
ポリシーが機能することを確認して、Enterを押します
この時点でも進行状況を確認して、ラボのポイントをさらに獲得できます
この時点で35ポイント中、約20ポイントを獲得できたはずです
タスク６では、バージョニングを有効にします
次のコマンドを使用して行います
“Suspended”と出力されているので、有効にされていません
バージョニングを有効にするには、このコマンドを実行します
次に、“get”コマンドを再度実行します
今度は“Suspended”ではなく、“Enabled”と出力されます
ここでも進行状況を確認すると、ポイントを獲得できます
次は、バケット内でサンプルファイルの複数のバージョンを作成します
最初に“ls”を実行します
setup.htmlファイルを開きます
任意の５行を削除して、ファイルのサイズを変更します
そのために、リンクをコメントアウトします
このリンクです
次に、これらのリンクをすべて削除します
このようにDeleteを押し続けるより、速い方法はあると思います
バナーまですべて削除していきます
実質的にファイルのサイズを変更しています
Ctrl+O、Enterキー、Ctrl+Xを押します
ファイルをバケットにコピーします
次に、setup.htmlに戻ります
別の５行を削除します
さらにリンクを削除します
ここまで削除します
保存します
そして、またコピーします
ファイルの全バージョンをリストします
順に異なる行を削除し、サイズを小さくして新しく作成したバージョンのリストです
オリジナルのファイル、最初の５行を削除したファイル、さらに別の行を削除したファイルの３つがあります
次の作業として、バージョンの値を格納する環境変数を作成するために、“export VERSION_NAME=”と入力します
一番古いバージョンはこれです
これをコピーして、この環境変数を設定し、正しく設定されていることを確認します
正しく設定されています
一番古いバージョンをダウンロードします
recovered.txtという名前にします
いくつかのコマンドで、復元されたことを確認します
どうなるか見てみましょう
“ls -al setup.html”を実行します
これではうまくいかなかったようです
どうやら、私が誤ったバージョン名を設定したようです
正しいのはこれです
これでもう一度gsutilを実行します
まだ一致していません
私のように手順に従わないとこうなります
完全なURLをコピーする必要があります
オブジェクトの完全なURLです
一般的に、ラボで問題が起こる原因は、ラボが壊れているためではなくステップを飛ばしたせいです
３つ前のステップから繰り返すと、たいていは解決します
ここでもそうです
“ls -al setup.html”を実行します
このファイルに対応するrecovered.txtを確認します
ご覧のようにサイズが異なります
タスク７では、ディレクトリをバケットと同期するので、これらをコピーします
VM上の最上位レベルのディレクトリをバケットと同期します
バージョニングが有効にされているか、確認します
ブラウザで確認できるので、バケットを更新します
最上位レベルに戻ります
第２レベルが表示されます
コマンドラインで確認したのと同じことをConsoleでも確認できます
Cloud Shellを終了します
次はプロジェクト間での共有です
このラボでの最後の作業です
別のタブを開いて、console.cloud.google.comに移動します
ログインします
これで、ログインされたら別のプロジェクトを選びます
末尾が26のプロジェクトです
Qwiklabsからプロジェクトをコピーします
サイトのラボガイドから、該当するプロジェクトを選択します
これは私の別のプロジェクトです
次に、このプロジェクト用のバケットを作成します
新しいプロジェクトなので、バケットはありません
“myproj”という名前にして、このプロジェクトIDを続けます
作成します
これが２つ目のバケット名です
ファイルをアップロードします
任意のファイルです
スクリーンショットをアップロードしました
これがファイル名になるので名前を変更します
変更できませんでした
次はIAMに移動します
[サービスアカウント]を選択してサービスアカウントを作成します
“cross-project-storage”という名前にします
Storageのロールを付与します
[Storageオブジェクト閲覧者]を選んで[続行]をクリックします
鍵を作成します
[JSON]を選んで、[作成]をクリックします
これで鍵ファイルがダウンロードされます
[閉じる]をクリックします
[完了]をクリックします
次に行うのは、名前の変更です
“credentials.json”に変更します
この名前です
もう一方のプロジェクトに戻って、進行状況を確認します
さらに５ポイント獲得できるので、ラボの完了まで残り５ポイントです
プロジェクトID“１”にいる間にVMを作成します
[作成]を押し、“crossproject”という名前にして欧州に作成します
dゾーン内でマイクロVMを作成します
[作成]をクリックします
これで、VMの準備ができたらSSHで接続します
[SSH]をクリックします
ウィンドウをここに戻します
プロジェクト用に作成したバケットの名前が必要です
機能するかどうか確認します
“export”の後に、アップロードしたファイルの名前を続けます
名前をコピーしましょう
スペースが含まれているので引用符で囲みます
これでうまくいきます
ありました
“ls”でバケットの内容を確認します
こちら側のVMから、その権限はないと拒否されるはずです
それを確認します
ここからアップロードします
[ファイルをアップロード]です
ここで選択するのは、先ほどダウンロードしたcredentials.jsonです
これを閉じてから、このファイルを指定して操作を認可します
アクセスできることを確認するために、“ls”を再実行します
今回はバケット内のファイルを確認できます
ファイルの内容も確認できます
次に試すのは、これらの認証情報のコピーです
このプロジェクトに対する、アクセス権がないと示されます
アクセス権を取得するにはプロジェクトに戻り、IAMでロールを変更します
これが最後のステップです
[IAM]に戻ります
“cross-project-storage”を選択します
鉛筆アイコンをクリックします
前と同じ操作で、Storageのオブジェクト管理者のロールを付与して、保存します
[保存]をクリックした後、進行状況を確認できます
これでこのラボのすべてのポイントを獲得できます
最後のステップは省略可能で、SSHターミナルに戻ってすべてが運用可能であることを確認するだけですが、チュートリアル全体を完了できるのでぜひ挑戦してください
